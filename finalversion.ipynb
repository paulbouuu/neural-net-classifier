{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to get familiar with our data, let's explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              images  labels\n",
      "0  [[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...  [none]\n",
      "1  [[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...  [none]\n",
      "2  [[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...  [none]\n",
      "3  [[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...  [none]\n",
      "4  [[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...  [none]\n",
      "[none]         13489\n",
      "[Loc]            297\n",
      "[Edge-Loc]       296\n",
      "[Center]          90\n",
      "[Random]          74\n",
      "[Scratch]         72\n",
      "[Edge-Ring]       31\n",
      "[Near-full]       16\n",
      "[Donut]            1\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_pickle('waferImg26x26.pkl')\n",
    "images = df.images.values\n",
    "labels = df.labels.values\n",
    "labels = np.asarray([str(l[0]) for l in labels])\n",
    "\n",
    "print(df.head())\n",
    "print(df['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label part is pretty clear, most wafers don't have any \"default\", it corresponds to the label 'none'.\n",
    "The other defaults are listed, they should correspond to where the default is located.\n",
    "\n",
    "Let's try to visualize an image. First, how is the image represented ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]\n",
      "  [1. 1. 1. ... 1. 1. 1.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(df['images'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image is composed of 3 arrays, they correspond to each color (RGB representation).\n",
    "Each array must be of size 26x26 but let's check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676\n",
      "676\n",
      "676\n",
      "676\n"
     ]
    }
   ],
   "source": [
    "print(df['images'][0][0].size)\n",
    "print(df['images'][0][1].size)\n",
    "print(df['images'][0][2].size)\n",
    "print(26*26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We indeed have 3 arrays of 26 by 26, representing each RGB color.\n",
    "\n",
    "Now let's visualize one image with matplotlib. We just have to transpose data to make it compatible with plt.imshow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "first_image_data = df.iloc[0]['images']\n",
    "\n",
    "transposed_image_data = np.transpose(first_image_data, (1, 2, 0))      #transpose to make it compatible with plt.imshow\n",
    "\n",
    "plt.imshow(transposed_image_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It corresponds to what we must find, the image of the pdf is the first image of the dataset. Let's explore the different label categories :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find image of a specific label among :\n",
    "# [none]         13489\n",
    "# [Loc]            297\n",
    "# [Edge-Loc]       296\n",
    "# [Center]          90\n",
    "# [Random]          74\n",
    "# [Scratch]         72\n",
    "# [Edge-Ring]       31\n",
    "# [Near-full]       16\n",
    "# [Donut]            1\n",
    "wanted_label = 'Edge-Ring'\n",
    "loc_images_df = df[df['labels'] == wanted_label]\n",
    "\n",
    "if not loc_images_df.empty:\n",
    "    loc_image_data = loc_images_df.iloc[0]['images']\n",
    "    # print(loc_image_data[0],type(loc_image_data[0]))\n",
    "    # print(\"\\n\",loc_image_data[1],type(loc_image_data[1]))\n",
    "    # print(\"\\n\",loc_image_data[2],type(loc_image_data[2]))\n",
    "\n",
    "    plt.imshow(np.transpose(loc_image_data, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are pretty explicit, \"Donut\" returns a donut shape on the wafer, \"Edge-Ring\" returns a semi circle on the edge of the wafer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (12929, 26, 26, 3)\n",
      "y_train shape: (12929, 9)\n",
      "x_test shape: (1437, 26, 26, 3)\n",
      "y_test shape: (1437, 9)\n",
      "number of classes: 9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "images = np.array([np.transpose(img, (1, 2, 0)) for img in images])\n",
    "\n",
    "# we have to encode labels to transform them into vectors, then to turn them into categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "categorical_encoded_labels = to_categorical(integer_encoded)    # labels are represented by vectors with 0s and a single 1\n",
    "\n",
    "num_classes = categorical_encoded_labels.shape[1]    # how many labels there are\n",
    "\n",
    "# we choose to use 10% of the data to test the accuracy, and 90% to train\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, categorical_encoded_labels, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "print(f\"number of classes: {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input shape will therefore be (26, 26, 3), the number of classes is correct, we can now build our model and start the \n",
    "training.\n",
    "\n",
    "First we will choose basic parameters, we will try to play with them later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 24, 24, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 12, 12, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 10, 10, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 5, 5, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 1, 1, 128)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 9)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110921 (433.29 KB)\n",
      "Trainable params: 110921 (433.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "405/405 [==============================] - 16s 36ms/step - loss: 0.3154 - accuracy: 0.9377 - val_loss: 0.2603 - val_accuracy: 0.9429\n",
      "Epoch 2/10\n",
      "405/405 [==============================] - 15s 37ms/step - loss: 0.2250 - accuracy: 0.9465 - val_loss: 0.1937 - val_accuracy: 0.9527\n",
      "Epoch 3/10\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.1981 - accuracy: 0.9513 - val_loss: 0.1912 - val_accuracy: 0.9457\n",
      "Epoch 4/10\n",
      "405/405 [==============================] - 14s 35ms/step - loss: 0.1742 - accuracy: 0.9551 - val_loss: 0.1906 - val_accuracy: 0.9450\n",
      "Epoch 5/10\n",
      "405/405 [==============================] - 15s 37ms/step - loss: 0.1595 - accuracy: 0.9565 - val_loss: 0.1655 - val_accuracy: 0.9527\n",
      "Epoch 6/10\n",
      "405/405 [==============================] - 16s 40ms/step - loss: 0.1477 - accuracy: 0.9604 - val_loss: 0.1589 - val_accuracy: 0.9582\n",
      "Epoch 7/10\n",
      "405/405 [==============================] - 16s 40ms/step - loss: 0.1416 - accuracy: 0.9612 - val_loss: 0.1549 - val_accuracy: 0.9589\n",
      "Epoch 8/10\n",
      "405/405 [==============================] - 14s 35ms/step - loss: 0.1254 - accuracy: 0.9653 - val_loss: 0.1586 - val_accuracy: 0.9610\n",
      "Epoch 9/10\n",
      "405/405 [==============================] - 16s 40ms/step - loss: 0.1114 - accuracy: 0.9669 - val_loss: 0.1466 - val_accuracy: 0.9617\n",
      "Epoch 10/10\n",
      "405/405 [==============================] - 16s 39ms/step - loss: 0.0958 - accuracy: 0.9708 - val_loss: 0.1580 - val_accuracy: 0.9589\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.1580 - accuracy: 0.9589\n",
      "Test loss: 0.15803539752960205\n",
      "Test accuracy: 0.9589422345161438\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(26, 26, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "95% accuracy is not bad, but not great either\n",
    "\n",
    "Moreover, by looking at the labels distribution :\n",
    "[none]         13489\n",
    "[Loc]            297\n",
    "[Edge-Loc]       296\n",
    "[Center]          90\n",
    "[Random]          74\n",
    "[Scratch]         72\n",
    "[Edge-Ring]       31\n",
    "[Near-full]       16\n",
    "[Donut]            1\n",
    "\n",
    "We can suspect that the model will be poorly rained to recognize \"Donut\", and maybe \"Near-full\" too. Let's check this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wanted_label = 'Donut'\n",
    "loc_images_df = df[df['labels'] == wanted_label]\n",
    "\n",
    "if not loc_images_df.empty:\n",
    "    loc_image_data = loc_images_df.iloc[0]['images']\n",
    "    # print(loc_image_data[0],type(loc_image_data[0]))\n",
    "    # print(\"\\n\",loc_image_data[1],type(loc_image_data[1]))\n",
    "    # print(\"\\n\",loc_image_data[2],type(loc_image_data[2]))\n",
    "\n",
    "    plt.imshow(np.transpose(loc_image_data, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's put this image in our model to see what it would predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "transposed_loc_image_data = np.transpose(loc_image_data, (1, 2, 0))\n",
    "#print(transposed_loc_image_data)\n",
    "\n",
    "#print(\"\\n\\nTraining dataset:\\n\", x_train)\n",
    "\n",
    "print(transposed_loc_image_data in x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Donut\" image is even in the training dataset. Let's see if the model can guess right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 109ms/step\n",
      "The model predicts Edge-Loc with a probability of 0.8830438852310181\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_image_batch = np.expand_dims(transposed_loc_image_data, axis=0)\n",
    "\n",
    "predictions = model.predict(test_image_batch)\n",
    "\n",
    "predicted_class_index = np.argmax(predictions, axis=1)\n",
    "\n",
    "predicted_class_label = label_encoder.inverse_transform(predicted_class_index)    #re transpose back\n",
    "\n",
    "predicted_probability = np.max(predictions, axis=1)\n",
    "\n",
    "print(f\"The model predicts {predicted_class_label[0]} with a probability of {predicted_probability[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is terrible for \"Donut\", but it was obvious because there was only one \"Donut\" image to train.\n",
    "\n",
    "What about categories that have more (or way more) occurences ?\n",
    "\n",
    "Let's try for \"Loc\" (297 occurences), \"Center\" (90) and \"Edge-Ring\" (31).\n",
    "\n",
    "First let's see how the labels are encoded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center: 0\n",
      "Donut: 1\n",
      "Edge-Loc: 2\n",
      "Edge-Ring: 3\n",
      "Loc: 4\n",
      "Near-full: 5\n",
      "Random: 6\n",
      "Scratch: 7\n",
      "none: 8\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "The model predicts Edge-Loc with a probability of 0.7736133337020874\n"
     ]
    }
   ],
   "source": [
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "for label, encoded_label in label_mapping.items():\n",
    "    print(f\"{label}: {encoded_label}\")\n",
    "\n",
    "L = np.array([0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
    "\n",
    "# for k in range(1000):         #determination of an image \"Loc\"\n",
    "#     if np.array_equal(y_test[k], L):\n",
    "#         print(k)\n",
    "\n",
    "# 233\n",
    "# 297\n",
    "# 376\n",
    "# 377\n",
    "\n",
    "x_test[233]\n",
    "\n",
    "test_image_batch = np.expand_dims(x_test[233], axis=0)\n",
    "\n",
    "predictions = model.predict(test_image_batch)\n",
    "\n",
    "predicted_class_index = np.argmax(predictions, axis=1)\n",
    "\n",
    "predicted_class_label = label_encoder.inverse_transform(predicted_class_index)    #re transpose back\n",
    "\n",
    "predicted_probability = np.max(predictions, axis=1)\n",
    "\n",
    "print(f\"The model predicts {predicted_class_label[0]} with a probability of {predicted_probability[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model predicted wrong but still it is a Loc default. Let's try with \"Center\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center: 0\n",
      "Donut: 1\n",
      "Edge-Loc: 2\n",
      "Edge-Ring: 3\n",
      "Loc: 4\n",
      "Near-full: 5\n",
      "Random: 6\n",
      "Scratch: 7\n",
      "none: 8\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "The model predicts none with a probability of 0.6262046098709106\n"
     ]
    }
   ],
   "source": [
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "for label, encoded_label in label_mapping.items():\n",
    "    print(f\"{label}: {encoded_label}\")\n",
    "\n",
    "L = np.array([1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "# for k in range(1000):         #determination of an image \"Center\"\n",
    "#     if np.array_equal(y_test[k], L):\n",
    "#         print(k)\n",
    "\n",
    "# 4\n",
    "# 346\n",
    "# 945\n",
    "\n",
    "x_test[346]\n",
    "\n",
    "test_image_batch = np.expand_dims(x_test[346], axis=0)\n",
    "\n",
    "predictions = model.predict(test_image_batch)\n",
    "\n",
    "predicted_class_index = np.argmax(predictions, axis=1)\n",
    "\n",
    "predicted_class_label = label_encoder.inverse_transform(predicted_class_index)    #re transpose back\n",
    "\n",
    "predicted_probability = np.max(predictions, axis=1)\n",
    "\n",
    "print(f\"The model predicts {predicted_class_label[0]} with a probability of {predicted_probability[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't work well with \"Center\" either, we should increase the number of default images to increase accuracy.\n",
    "\n",
    "Let's try to change the parameters of our CNN.\n",
    "\n",
    "What can we change ?\n",
    "- the loss function\n",
    "- the CNN structure\n",
    "- the activation\n",
    "- the optimizer\n",
    "- the dropout\n",
    "- the epochs\n",
    "- the batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 24, 24, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPooli  (None, 12, 12, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 10, 10, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPooli  (None, 5, 5, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPooli  (None, 1, 1, 128)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 9)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110921 (433.29 KB)\n",
      "Trainable params: 110921 (433.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "405/405 [==============================] - 14s 30ms/step - loss: 0.3050 - accuracy: 0.9394 - val_loss: 0.2594 - val_accuracy: 0.9457\n",
      "Epoch 2/10\n",
      "405/405 [==============================] - 13s 32ms/step - loss: 0.2129 - accuracy: 0.9498 - val_loss: 0.1914 - val_accuracy: 0.9513\n",
      "Epoch 3/10\n",
      "405/405 [==============================] - 13s 32ms/step - loss: 0.1810 - accuracy: 0.9533 - val_loss: 0.1715 - val_accuracy: 0.9555\n",
      "Epoch 4/10\n",
      "405/405 [==============================] - 13s 33ms/step - loss: 0.1613 - accuracy: 0.9589 - val_loss: 0.1874 - val_accuracy: 0.9569\n",
      "Epoch 5/10\n",
      "405/405 [==============================] - 13s 33ms/step - loss: 0.1465 - accuracy: 0.9623 - val_loss: 0.1598 - val_accuracy: 0.9548\n",
      "Epoch 6/10\n",
      "405/405 [==============================] - 14s 33ms/step - loss: 0.1416 - accuracy: 0.9639 - val_loss: 0.1568 - val_accuracy: 0.9582\n",
      "Epoch 7/10\n",
      "405/405 [==============================] - 16s 39ms/step - loss: 0.1250 - accuracy: 0.9666 - val_loss: 0.1728 - val_accuracy: 0.9582\n",
      "Epoch 8/10\n",
      "405/405 [==============================] - 14s 35ms/step - loss: 0.1132 - accuracy: 0.9671 - val_loss: 0.1558 - val_accuracy: 0.9569\n",
      "Epoch 9/10\n",
      "405/405 [==============================] - 13s 33ms/step - loss: 0.0951 - accuracy: 0.9712 - val_loss: 0.1627 - val_accuracy: 0.9652\n",
      "Epoch 10/10\n",
      "405/405 [==============================] - 14s 34ms/step - loss: 0.0774 - accuracy: 0.9752 - val_loss: 0.2138 - val_accuracy: 0.9624\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.2138 - accuracy: 0.9624\n",
      "Test loss: 0.21376095712184906\n",
      "Test accuracy: 0.962421715259552\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(26, 26, 3)))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dropout(0.35))\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dense(num_classes, activation='softmax'))\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model2.summary()\n",
    "\n",
    "model2.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "score2 = model2.evaluate(x_test, y_test)\n",
    "print('Test loss:', score2[0])\n",
    "print('Test accuracy:', score2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By reducing the dropout from 50 to 35%, we have obtained a slightly better accuracy but it may not be significant.\n",
    "On this training, the accuracy of the epoch 9/10 is better than the one of the epoch 10/10, so increase the number of epochs shouldn't be very relevant.\n",
    "\n",
    "Let's try to change the optimizer, we will take RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "405/405 [==============================] - 15s 32ms/step - loss: 0.2940 - accuracy: 0.9414 - val_loss: 0.2191 - val_accuracy: 0.9464\n",
      "Epoch 2/10\n",
      "405/405 [==============================] - 13s 31ms/step - loss: 0.2077 - accuracy: 0.9499 - val_loss: 0.1923 - val_accuracy: 0.9513\n",
      "Epoch 3/10\n",
      "405/405 [==============================] - 13s 33ms/step - loss: 0.1794 - accuracy: 0.9544 - val_loss: 0.1750 - val_accuracy: 0.9548\n",
      "Epoch 4/10\n",
      "405/405 [==============================] - 14s 34ms/step - loss: 0.1625 - accuracy: 0.9590 - val_loss: 0.1761 - val_accuracy: 0.9589\n",
      "Epoch 5/10\n",
      "405/405 [==============================] - 13s 33ms/step - loss: 0.1491 - accuracy: 0.9608 - val_loss: 0.1676 - val_accuracy: 0.9596\n",
      "Epoch 6/10\n",
      "405/405 [==============================] - 13s 33ms/step - loss: 0.1369 - accuracy: 0.9649 - val_loss: 0.1786 - val_accuracy: 0.9492\n",
      "Epoch 7/10\n",
      "405/405 [==============================] - 13s 33ms/step - loss: 0.1231 - accuracy: 0.9660 - val_loss: 0.1767 - val_accuracy: 0.9589\n",
      "Epoch 8/10\n",
      "405/405 [==============================] - 13s 33ms/step - loss: 0.1122 - accuracy: 0.9679 - val_loss: 0.1642 - val_accuracy: 0.9562\n",
      "Epoch 9/10\n",
      "405/405 [==============================] - 13s 33ms/step - loss: 0.1012 - accuracy: 0.9705 - val_loss: 0.1816 - val_accuracy: 0.9624\n",
      "Epoch 10/10\n",
      "405/405 [==============================] - 14s 34ms/step - loss: 0.0929 - accuracy: 0.9731 - val_loss: 0.2108 - val_accuracy: 0.9624\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.2108 - accuracy: 0.9624\n",
      "Test loss: 0.21075183153152466\n",
      "Test accuracy: 0.962421715259552\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(26, 26, 3)))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dropout(0.35))\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "model3.add(Dense(num_classes, activation='softmax'))\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])    # new optimizer\n",
    "\n",
    "\n",
    "model3.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "score3 = model3.evaluate(x_test, y_test)\n",
    "print('Test loss:', score3[0])\n",
    "print('Test accuracy:', score3[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy we got is pretty much the same as the last model but the optimizer 'RMSprop' seems also interesting to use.\n",
    "\n",
    "The parameters we still have not changed are :\n",
    "\n",
    "- the loss function\n",
    "- the CNN structure\n",
    "- the activation\n",
    "- the batch size\n",
    "\n",
    "For this classification problem, the loss function we used ('categorical_crossentropy') is usally the best choice.\n",
    "ReLu functions are also a pretty good solution, we could change our CNN structure and maybe add layers, but we would risk overfitting.\n",
    "Let's try changing the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "203/203 [==============================] - 14s 60ms/step - loss: 0.3414 - accuracy: 0.9360 - val_loss: 0.2364 - val_accuracy: 0.9450\n",
      "Epoch 2/10\n",
      "203/203 [==============================] - 12s 58ms/step - loss: 0.2241 - accuracy: 0.9474 - val_loss: 0.2099 - val_accuracy: 0.9436\n",
      "Epoch 3/10\n",
      "203/203 [==============================] - 11s 56ms/step - loss: 0.1875 - accuracy: 0.9527 - val_loss: 0.1774 - val_accuracy: 0.9562\n",
      "Epoch 4/10\n",
      "203/203 [==============================] - 12s 57ms/step - loss: 0.1734 - accuracy: 0.9552 - val_loss: 0.1706 - val_accuracy: 0.9541\n",
      "Epoch 5/10\n",
      "203/203 [==============================] - 12s 59ms/step - loss: 0.1627 - accuracy: 0.9592 - val_loss: 0.1730 - val_accuracy: 0.9548\n",
      "Epoch 6/10\n",
      "203/203 [==============================] - 12s 58ms/step - loss: 0.1523 - accuracy: 0.9627 - val_loss: 0.1626 - val_accuracy: 0.9555\n",
      "Epoch 7/10\n",
      "203/203 [==============================] - 12s 60ms/step - loss: 0.1403 - accuracy: 0.9630 - val_loss: 0.1691 - val_accuracy: 0.9576\n",
      "Epoch 8/10\n",
      "203/203 [==============================] - 12s 61ms/step - loss: 0.1331 - accuracy: 0.9648 - val_loss: 0.1443 - val_accuracy: 0.9589\n",
      "Epoch 9/10\n",
      "203/203 [==============================] - 12s 59ms/step - loss: 0.1209 - accuracy: 0.9662 - val_loss: 0.1451 - val_accuracy: 0.9596\n",
      "Epoch 10/10\n",
      "203/203 [==============================] - 12s 60ms/step - loss: 0.1122 - accuracy: 0.9681 - val_loss: 0.1357 - val_accuracy: 0.9652\n",
      "45/45 [==============================] - 0s 10ms/step - loss: 0.1357 - accuracy: 0.9652\n",
      "Test loss: 0.13568878173828125\n",
      "Test accuracy: 0.9652053117752075\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model4 = Sequential()\n",
    "\n",
    "model4.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(26, 26, 3)))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model4.add(Flatten())\n",
    "model4.add(Dropout(0.35))\n",
    "model4.add(Dense(128, activation='relu'))\n",
    "model4.add(Dense(num_classes, activation='softmax'))\n",
    "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model4.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test))    # batch size from 32 to 64\n",
    "\n",
    "score4 = model4.evaluate(x_test, y_test)\n",
    "print('Test loss:', score4[0])\n",
    "print('Test accuracy:', score4[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the batch size seem to have improved the accuracy, the accuracy has nearly increased at every epoch, so maybe we could add a few epochs to the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally obtained an accuracy of 96.5%, it is pretty satisfying, but some more fine parameters could still be changed to make progress, such as :\n",
    "- the CNN structure\n",
    "- the activation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
